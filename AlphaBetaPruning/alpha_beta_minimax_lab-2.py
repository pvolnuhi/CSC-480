# -*- coding: utf-8 -*-
"""Alpha-Beta Minimax Lab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Slcq_mI380K4tx2dyk5JcNNnLceLjwN_

## Minimax with Alpha-Beta Pruning
As seen in Lab 5, Minimax is an algorithm that makes optimal moves by minimizing the loss, assuming the other player is playing optimally. However, optimiality comes with the cost of exploring many game states, which can be costly in large search spaces. In this section you will implement Minimax with Alpah-Beta pruning for tic tac toe.

### Introduction
Minimax will always find the solution, at the expense of exploring every game state. By using Alpha-Beta pruning, this search space is reduced. In this lab, you will implement this method for the game of tic tac toe.



Observe the following tic tac toe board:
"""

import numpy as np
example_board = np.array([[' ', ' ', ' '],
                          [' ', ' ', ' '],
                          [' ', ' ', ' ']])
print(example_board)

"""***
### Get Possible Boards
This function generates all possible moves for the given board and player. It will place an 'O' for the maximizing player and 'X' for the minimizing player. Observe the generated boards.
"""

# Calculates all successor states to a given state
def get_possible_moves(board, player):
    moves = []
    for (x, y), element in np.ndenumerate(board):
        if element == ' ':
            new_board = np.array(board, copy=True)
            new_board[x][y] = 'X' if player is 'max' else 'O'
            moves.append(new_board)
    return moves

example_moves = get_possible_moves(example_board, 'max')
for b in example_moves:
  print(b)

"""***
### Get Score
This function calculates the game score to be either:
1. Max victory - value greater than one
2. Min victory -value less than one
3. Draw - value of zero
4. Incomplete - value of None

It scales by the depth of the search in order to delay losing as long as possible and win as quickly as possible.
"""

def get_score(board, depth=0):
    if (np.any(np.all(board == 'X', axis=0)) or 
        np.any(np.all(board == 'X', axis=1)) or 
        np.all(board.diagonal() == 'X') or 
        np.all(np.fliplr(board).diagonal() == 'X')):
        # Max Victory
        return 1 * (1 / (1 + depth))
    elif (np.any(np.all(board == 'O', axis=0)) or 
          np.any(np.all(board == 'O', axis=1)) or
          np.all(board.diagonal() == 'O') or 
          np.all(np.fliplr(board).diagonal() == 'O')):
        # Min Victory
        return -1 * (1 / (1 + depth))
    elif not (board == ' ').any():
        # Draw
        return 0
    else:
        # Unfinished Game
        return None


tests = np.array([[['O', 'X', ' '],
                   ['O', 'O', 'X'],
                   ['X', ' ', 'O']],
                  [['X', 'O', 'O'],
                   ['O', 'X', 'O'],
                   [' ', ' ', 'X']],
                  [['O', 'O', 'X'],
                   ['X', 'X', 'O'],
                   ['O', 'X', 'O']],
                  [['O', 'X', ' '],
                   ['O', 'O', 'X'],
                   ['X', ' ', ' ']]])
                
for test in tests:
  print(test, get_score(test))

"""***
### Find Value
Your task is the implement value function, which will return the value of the board calcuated using minimax. To recieve full credit, this function must use alpha beta pruning.  A skeleton has been provided for you:


* **board:** the tic tac toe board that must be evalutated
* **alpha:** the current alpha parameter of the search
* **beta:** the current beta parameter of the search
* **player:** the current player who is acting
* **depth:** how deep in the tree we are from the initial call




*Hint: Use this function recursively for each node of the game tree*
"""

# Finds the integer expected score of a game state using minimax with alpha-beta
def find_value(board, player, alpha=float('-inf'), beta=float('inf'), depth=0):
    
    boards = get_possible_moves(board, player)
    
    if get_score(board) is not None:
      return get_score(board)

    if player is 'max':
      maxValue = alpha
      for child in boards:
        val = find_value(child, 'min', alpha, beta, depth + 1)
        maxValue = max(maxValue, val)
        alpha = max(alpha, val)
        if beta <= alpha:
          break
      return maxValue
    else:
      minValue = beta
      for child in boards:
        val = find_value(child, 'max', alpha, beta, depth + 1)
        minValue = max(minValue, val)
        beta = min(beta, val)
        if beta <= alpha:
          break
      return minValue

"""***
### Find Best Move
We will now use our value finder in order to calculate the value of all possible moves and choose the best one.
"""

# Finds the best move (state with highest/lowest value)
from tqdm import tqdm_notebook as tqdm
def find_best_move(board, player):
    print("Deciding best move...")
    boards = get_possible_moves(board, player)
    values = [find_value(board, 
                         ('max' if player is 'min' 
                          else 'min'))
              for board in tqdm(boards)]
    if None in values:
        raise ValueError('find_value should always return an integer.')
    if player is "max":
        policy_vector = np.array([1 if value == np.amax(values) else 0
                                  for value in values])    
    else:
        policy_vector = np.array([1 if value == np.amin(values) else 0
                                  for value in values])
    # Normalize Probabilities 
    policy_vector = policy_vector / np.count_nonzero(policy_vector)
    return boards[np.random.choice(np.arange(len(values)),
                                   1, 
                                   p=policy_vector)[0]]

test_boards = [[['X', 'O', ' '],
                ['O', 'X', ' '],
                [' ', ' ', ' ']]]
print(test_boards[0])
print(find_best_move(test_boards[0], 'max'))

"""***
### Testing
In order to test our AI, we can play a few games against it:
"""

def run_demo():
  board = np.array([[' ', ' ', ' '],
                    [' ', ' ', ' '],
                    [' ', ' ', ' ']])
  score = get_score(board)
  player = "max"
  while score is None:
      if player == "max":
          board = find_best_move(board, player)
      else:
          move_entered = False
          while not move_entered:
              try:
                  move = int(input('Choose a move...')) - 1
                  if not 0 <= move <= 8:
                      print("Enter an integer between 1 and 9.\n")
                      continue
                  elif not board[move//3][move%3] == ' ':
                      print("That spot is already taken.\n")
                      continue
                  else:
                      board[move//3][move%3]= 'O'
                      move_entered = True
              except ValueError:
                  print("Enter an integer.\n")
      score = get_score(board)
      player = "min" if player == "max" else "max"
      print(board)
  if (score == 0):
      print("Draw")
  elif (score > 0):
      print("You Lose")
  else:
      print("You Win")
      
      
run_demo()

